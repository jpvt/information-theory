{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_headers():\n",
    "#     for i in range(1,41):\n",
    "#         for j in range(1,11):\n",
    "#             with open(f\"test/data/orl_faces/s{i}/{j}.pgm\", \"rb\") as f:\n",
    "#                 lines = f.readlines()\n",
    "            \n",
    "#             with open(f\"test/data/processed_orl_faces/s{i}/{j}.pgm\", \"wb\") as processed_f:\n",
    "#                 processed_f.writelines(lines[3:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression.helpers import read_data\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images():\n",
    "    images = []\n",
    "    for i in range(1,41):\n",
    "        person_images = []\n",
    "        for j in range(1,11):\n",
    "            person_images.append(read_data(f\"test/data/orl_faces/s{i}/{j}.pgm\")[0])\n",
    "        images.append(person_images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(images):\n",
    "    training_images = []\n",
    "    test_images = []\n",
    "\n",
    "    for i in range(0,len(images)):\n",
    "        test_index = np.random.choice(10)\n",
    "        training_images.append(images[i].pop(test_index))\n",
    "        test_images.append(images[i])\n",
    "    return training_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression.lzw import LZW\n",
    "\n",
    "\n",
    "def train(images, dicts, k):\n",
    "    lzw = LZW(dictionary_k=k)\n",
    "    data_set = {i for i in range(2**8)}\n",
    "    for i, person_images in enumerate(images):\n",
    "        for image in person_images:\n",
    "                _, dicts[i], _ = lzw.encode(image, data_set.copy(), existing_dict=dicts[i], incremental=True)\n",
    "\n",
    "    return dicts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_images, dicts, k, verbose: bool) -> float:\n",
    "    lzw = LZW(dictionary_k=k)\n",
    "    data_set = {i for i in range(2**8)}\n",
    "    accuracy_result = []\n",
    "    \n",
    "    for i, image in enumerate(test_images):\n",
    "        compression_size = []\n",
    "\n",
    "        for j in range(40):\n",
    "            output, _ = lzw.encode(image, data_set, existing_dict=dicts[j], incremental=False) # needs required arguments\n",
    "            compression_size.append(len(output))\n",
    "\n",
    "        accuracy_result.append(i  == compression_size.index(min(compression_size)))\n",
    "    \n",
    "    accuracy = 100 * accuracy_result.count(True) / len(accuracy_result)\n",
    "    if verbose:\n",
    "        print(f\"Modelo com acur√°cia para k = {k}: {accuracy}%\")\n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(images, k):\n",
    "    train_start = time()\n",
    "    dicts = []\n",
    "    data_set = {i for i in range(2**8)}\n",
    "    dictionary = {(value,): i for i, value in enumerate(data_set)}\n",
    "\n",
    "    for i in range(40):\n",
    "        dicts.append(dictionary.copy())\n",
    "\n",
    "    training_images, test_images = cross_validation(images)\n",
    "\n",
    "    dicts = train(training_images, dicts, k)\n",
    "\n",
    "    return test(test_images, dicts, k, verbose=True), time() - train_start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dictionary: {(0,): 0, (1,): 1, (2,): 2, (3,): 3, (4,): 4, (5,): 5, (6,): 6, (7,): 7, (8,): 8, (9,): 9, (10,): 10, (11,): 11, (12,): 12, (13,): 13, (14,): 14, (15,): 15, (16,): 16, (17,): 17, (18,): 18, (19,): 19, (20,): 20, (21,): 21, (22,): 22, (23,): 23, (24,): 24, (25,): 25, (26,): 26, (27,): 27, (28,): 28, (29,): 29, (30,): 30, (31,): 31, (32,): 32, (33,): 33, (34,): 34, (35,): 35, (36,): 36, (37,): 37, (38,): 38, (39,): 39, (40,): 40, (41,): 41, (42,): 42, (43,): 43, (44,): 44, (45,): 45, (46,): 46, (47,): 47, (48,): 48, (49,): 49, (50,): 50, (51,): 51, (52,): 52, (53,): 53, (54,): 54, (55,): 55, (56,): 56, (57,): 57, (58,): 58, (59,): 59, (60,): 60, (61,): 61, (62,): 62, (63,): 63, (64,): 64, (65,): 65, (66,): 66, (67,): 67, (68,): 68, (69,): 69, (70,): 70, (71,): 71, (72,): 72, (73,): 73, (74,): 74, (75,): 75, (76,): 76, (77,): 77, (78,): 78, (79,): 79, (80,): 80, (81,): 81, (82,): 82, (83,): 83, (84,): 84, (85,): 85, (86,): 86, (87,): 87, (88,): 88, (89,): 89, (90,): 90, (91,): 91, (92,): 92, (93,): 93, (94,): 94, (95,): 95, (96,): 96, (97,): 97, (98,): 98, (99,): 99, (100,): 100, (101,): 101, (102,): 102, (103,): 103, (104,): 104, (105,): 105, (106,): 106, (107,): 107, (108,): 108, (109,): 109, (110,): 110, (111,): 111, (112,): 112, (113,): 113, (114,): 114, (115,): 115, (116,): 116, (117,): 117, (118,): 118, (119,): 119, (120,): 120, (121,): 121, (122,): 122, (123,): 123, (124,): 124, (125,): 125, (126,): 126, (127,): 127, (128,): 128, (129,): 129, (130,): 130, (131,): 131, (132,): 132, (133,): 133, (134,): 134, (135,): 135, (136,): 136, (137,): 137, (138,): 138, (139,): 139, (140,): 140, (141,): 141, (142,): 142, (143,): 143, (144,): 144, (145,): 145, (146,): 146, (147,): 147, (148,): 148, (149,): 149, (150,): 150, (151,): 151, (152,): 152, (153,): 153, (154,): 154, (155,): 155, (156,): 156, (157,): 157, (158,): 158, (159,): 159, (160,): 160, (161,): 161, (162,): 162, (163,): 163, (164,): 164, (165,): 165, (166,): 166, (167,): 167, (168,): 168, (169,): 169, (170,): 170, (171,): 171, (172,): 172, (173,): 173, (174,): 174, (175,): 175, (176,): 176, (177,): 177, (178,): 178, (179,): 179, (180,): 180, (181,): 181, (182,): 182, (183,): 183, (184,): 184, (185,): 185, (186,): 186, (187,): 187, (188,): 188, (189,): 189, (190,): 190, (191,): 191, (192,): 192, (193,): 193, (194,): 194, (195,): 195, (196,): 196, (197,): 197, (198,): 198, (199,): 199, (200,): 200, (201,): 201, (202,): 202, (203,): 203, (204,): 204, (205,): 205, (206,): 206, (207,): 207, (208,): 208, (209,): 209, (210,): 210, (211,): 211, (212,): 212, (213,): 213, (214,): 214, (215,): 215, (216,): 216, (217,): 217, (218,): 218, (219,): 219, (220,): 220, (221,): 221, (222,): 222, (223,): 223, (224,): 224, (225,): 225, (226,): 226, (227,): 227, (228,): 228, (229,): 229, (230,): 230, (231,): 231, (232,): 232, (233,): 233, (234,): 234, (235,): 235, (236,): 236, (237,): 237, (238,): 238, (239,): 239, (240,): 240, (241,): 241, (242,): 242, (243,): 243, (244,): 244, (245,): 245, (246,): 246, (247,): 247, (248,): 248, (249,): 249, (250,): 250, (251,): 251, (252,): 252, (253,): 253, (254,): 254, (255,): 255}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_test(images,\u001b[39m9\u001b[39;49m)\n",
      "\u001b[1;32m/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb Cell 17\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(images, k)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     dicts\u001b[39m.\u001b[39mappend(dictionary\u001b[39m.\u001b[39mcopy())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m training_images, test_images \u001b[39m=\u001b[39m cross_validation(images)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m dicts \u001b[39m=\u001b[39m train(training_images, dicts, k)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m test(test_images, dicts, k, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb Cell 17\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(images, dicts, k)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, person_images \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(images):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m person_images:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             _, dicts[i], _ \u001b[39m=\u001b[39m lzw\u001b[39m.\u001b[39;49mencode(image, data_set\u001b[39m.\u001b[39;49mcopy(), existing_dict\u001b[39m=\u001b[39;49mdicts[i], incremental\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/itamar/Development/facul/ITI/information-theory/assignment_2.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dicts\n",
      "File \u001b[0;32m~/Development/facul/ITI/information-theory/compression/lzw.py:37\u001b[0m, in \u001b[0;36mLZW.encode\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStarting dictionary: \u001b[39m\u001b[39m{\u001b[39;00mdictionary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m output \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 37\u001b[0m current_arr \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moriginal_data[\u001b[39m0\u001b[39;49m],)\n\u001b[1;32m     38\u001b[0m next_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_set)\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m num \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_data[\u001b[39m1\u001b[39m:]:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "images = get_images()\n",
    "acc = []\n",
    "time = []\n",
    "\n",
    "for k in range(9,17):\n",
    "    accuracy, training_time = train_test(images, k)\n",
    "    acc.append(accuracy)\n",
    "    time.append(training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
